---
source: crates/ppcjit/src/test.rs
expression: disasm
---
  pushq %rbp
  unwind PushFrameRegs { offset_upward_to_caller_sp: 16 }
  movq %rsp, %rbp
  unwind DefineNewFrame { offset_upward_to_caller_sp: 16, offset_downward_to_clobbers: 48 }
  subq $0x110, %rsp
  movq %rbx, 0xe0(%rsp)
  unwind SaveReg { clobber_offset: 0, reg: p3i }
  movq %r12, 0xe8(%rsp)
  unwind SaveReg { clobber_offset: 8, reg: p12i }
  movq %r13, 0xf0(%rsp)
  unwind SaveReg { clobber_offset: 16, reg: p13i }
  movq %r14, 0xf8(%rsp)
  unwind SaveReg { clobber_offset: 24, reg: p14i }
  movq %r15, 0x100(%rsp)
  unwind SaveReg { clobber_offset: 32, reg: p15i }
block0:
  movq %rdi, <offset:1>+8(%rsp)
  movq %rsi, <offset:1>+0x10(%rsp)
  movl 0x2a8(%rdx), %eax
  movq %rdx, <offset:1>+0x18(%rsp)
  shrl $0xd, %eax
  testb $0x1, %al
  jnz     label2; j label1
block2:
  movq <offset:1>+0x18(%rsp), %rdi
  movl 0x14(%rdi), %ebx
  movl 0x368(%rdi), %edx
  movq %rdx, %r12
  leaq <offset:1>+(%rsp), %rcx
  movq %rcx, <offset:1>+0xd8(%rsp)
  load_ext_name userextname11+0, %r10
  movq %rbx, %rsi
  movq <offset:1>+0x10(%rsp), %rdi
  call    *%r10
  testb %al, %al
  jnz     label4; j label3
block4:
  vmovsd <offset:1>+(%rsp), %xmm6
  movdqu %xmm6, <offset:1>+0xc8(%rsp)
  movzbl %al, %r8d
  leal (%rbx, %r8), %r14d
  load_ext_name userextname11+0, %r8
  movq %r12, %rdx
  movq <offset:1>+0xd8(%rsp), %rcx
  movq %r14, %rsi
  movq <offset:1>+0x10(%rsp), %rdi
  call    *%r8
  testb %al, %al
  jnz     label6; j label5
block6:
  vmovsd <offset:1>+(%rsp), %xmm3
  movq <offset:1>+0x18(%rsp), %rdi
  movdqu %xmm3, <offset:1>+0xb8(%rsp)
  movl (%rdi), %r14d
  movl 0x18(%rdi), %r15d
  movl 0x368(%rdi), %edx
  movq %rdx, %r13
  load_ext_name userextname11+0, %rax
  movq <offset:1>+0xd8(%rsp), %rcx
  movq %r15, %rsi
  movq <offset:1>+0x10(%rsp), %rdi
  call    *%rax
  testb %al, %al
  jnz     label8; j label7
block8:
  vmovsd <offset:1>+(%rsp), %xmm5
  movdqu %xmm5, <offset:1>+0xa8(%rsp)
  movzbl %al, %eax
  leal (%r15, %rax), %r12d
  load_ext_name userextname11+0, %rax
  movq %r13, %rdx
  movq <offset:1>+0xd8(%rsp), %rcx
  movq %r12, %rsi
  movq <offset:1>+0x10(%rsp), %rdi
  call    *%rax
  testb %al, %al
  jnz     label10; j label9
block10:
  vmovsd <offset:1>+(%rsp), %xmm5
  movq <offset:1>+0x18(%rsp), %rdi
  movl 0x28c(%rdi), %edi
  movq %rdi, <offset:1>+0x90(%rsp)
  movq <offset:1>+0x18(%rsp), %rdi
  movl 0x1c(%rdi), %r12d
  movl 0x368(%rdi), %edx
  movq %rdx, <offset:1>+0x88(%rsp)
  uninit  %xmm3
  vxorpd %xmm3, %xmm3, %xmm6
  movdqu <offset:1>+0xc8(%rsp), %xmm7
  vmovsd %xmm7, %xmm6, %xmm7
  movdqu <offset:1>+0xb8(%rsp), %xmm3
  vmovlhps %xmm3, %xmm7, %xmm6
  uninit  %xmm3
  vxorpd %xmm3, %xmm3, %xmm0
  movdqu <offset:1>+0xa8(%rsp), %xmm7
  vmovsd %xmm7, %xmm0, %xmm0
  vmovlhps %xmm5, %xmm0, %xmm7
  movdqu %xmm5, <offset:1>+0x98(%rsp)
  vaddpd %xmm7, %xmm6, %xmm5
  movdqu %xmm5, <offset:1>+0x78(%rsp)
  load_ext_name userextname12+0, %rax
  movq %r12, %rsi
  movq <offset:1>+0x10(%rsp), %rdi
  movdqu <offset:1>+0x78(%rsp), %xmm0
  call    *%rax
  testb %al, %al
  jnz     label12; j label11
block12:
  movdqu <offset:1>+0x78(%rsp), %xmm5
  movzbl %al, %eax
  leal (%r12, %rax), %r13d
  vpshufd $0xee, %xmm5, %xmm0
  movdqu %xmm0, <offset:1>+0x68(%rsp)
  load_ext_name userextname12+0, %rcx
  movq <offset:1>+0x88(%rsp), %rdx
  movq %r13, %rsi
  movq <offset:1>+0x10(%rsp), %rdi
  call    *%rcx
  testb %al, %al
  jnz     label14; j label13
block14:
  movq <offset:1>+0x18(%rsp), %rdi
  movq <offset:1>+0x90(%rsp), %r13
  movl 0x368(%rdi), %edx
  leal 8(%rbx), %esi
  load_ext_name userextname11+0, %r8
  movq <offset:1>+0xd8(%rsp), %rcx
  movq <offset:1>+0x10(%rsp), %rdi
  call    *%r8
  testb %al, %al
  jnz     label16; j label15
block16:
  vmovsd <offset:1>+(%rsp), %xmm4
  movq <offset:1>+0x18(%rsp), %rdi
  movdqu %xmm4, <offset:1>+0x58(%rsp)
  movl 0x368(%rdi), %edx
  leal 8(%r15), %ebx
  load_ext_name userextname11+0, %rax
  movq <offset:1>+0xd8(%rsp), %rcx
  movq %rbx, %rsi
  movq <offset:1>+0x10(%rsp), %rdi
  call    *%rax
  testb %al, %al
  jnz     label18; j label17
block18:
  movdqu <offset:1>+0x58(%rsp), %xmm4
  vmovsd <offset:1>+(%rsp), %xmm1
  movq <offset:1>+0x18(%rsp), %rdi
  movl 0x368(%rdi), %edx
  leal 8(%r12), %r12d
  uninit  %xmm7
  vxorpd %xmm7, %xmm7, %xmm2
  vmovsd %xmm4, %xmm2, %xmm3
  movabsq $0x3ff0000000000000, %r8
  vmovq %r8, %xmm2
  vmovlhps %xmm2, %xmm3, %xmm3
  uninit  %xmm7
  vxorpd %xmm7, %xmm7, %xmm4
  vmovsd %xmm1, %xmm4, %xmm4
  movdqu %xmm1, <offset:1>+0x48(%rsp)
  vmovlhps %xmm2, %xmm4, %xmm1
  movdqu %xmm2, <offset:1>+0x38(%rsp)
  vaddpd %xmm1, %xmm3, %xmm1
  movdqu %xmm1, <offset:1>+0x28(%rsp)
  load_ext_name userextname12+0, %r8
  movq <offset:1>+0x10(%rsp), %rdi
  movq %r12, %rsi
  movdqu <offset:1>+0x28(%rsp), %xmm0
  call    *%r8
  testb %al, %al
  jnz     label20; j label19
block20:
  movq <offset:1>+0x18(%rsp), %rdi
  movdqu <offset:1>+0x28(%rsp), %xmm1
  movdqu <offset:1>+0x38(%rsp), %xmm2
  movdqu <offset:1>+0x48(%rsp), %xmm3
  movdqu <offset:1>+0x58(%rsp), %xmm4
  movdqu <offset:1>+0xc8(%rsp), %xmm6
  vmovsd %xmm6, 0xa8(%rdi)
  vmovsd %xmm3, 0xd8(%rdi)
  movdqu <offset:1>+0x98(%rsp), %xmm5
  vmovsd %xmm5, 0xd0(%rdi)
  vpshufd $0xee, %xmm1, %xmm3
  vmovsd %xmm3, 0x100(%rdi)
  leal 0x20(%r14), %eax
  movl %eax, (%rdi)
  vmovsd %xmm4, 0xb8(%rdi)
  movdqu <offset:1>+0xb8(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movl $0x1f000, %r11d
  uninit  %xmm4
  vxorpd %xmm4, %xmm4, %xmm6
  vucomisd %xmm1, %xmm6
  seta %r9b
  movzbl %r9b, %esi
  shll $0xf, %esi
  vucomisd (%rip), %xmm1
  seta %r10b
  movzbl %r10b, %r9d
  shll $0xe, %r9d
  orl %r9d, %esi
  vucomisd (%rip), %xmm1
  setnp %dil
  sete %cl
  andl %ecx, %edi
  movzbl %dil, %r10d
  shll $0xd, %r10d
  orl %r10d, %esi
  vucomisd (%rip), %xmm1
  setp %dil
  movzbl %dil, %edi
  shll $0xc, %edi
  orl %edi, %esi
  movdqu <offset:1>+0x78(%rsp), %xmm5
  vucomisd %xmm5, %xmm6
  seta %dil
  movzbl %dil, %edx
  shll $0xf, %edx
  vucomisd (%rip), %xmm5
  seta %al
  movzbl %al, %edi
  shll $0xe, %edi
  orl %edi, %edx
  vucomisd (%rip), %xmm5
  setnp %cl
  sete %r8b
  andl %r8d, %ecx
  movzbl %cl, %ecx
  shll $0xd, %ecx
  orl %ecx, %edx
  vucomisd (%rip), %xmm5
  setp %r8b
  movzbl %r8b, %ecx
  shll $0xc, %ecx
  orl %ecx, %edx
  movq %r11, %r8
  andl %edx, %r8d
  movq %r11, %rdx
  notl %edx
  andl %r13d, %edx
  orl %edx, %r8d
  movq %r11, %rdx
  andl %esi, %edx
  notl %r11d
  andl %r8d, %r11d
  orl %r11d, %edx
  movq <offset:1>+0x18(%rsp), %rdi
  movl %edx, 0x28c(%rdi)
  vmovsd %xmm5, 0xe8(%rdi)
  vmovsd %xmm2, 0xe0(%rdi)
  movdqu <offset:1>+0xa8(%rsp), %xmm5
  vmovsd %xmm5, 0xc8(%rdi)
  vmovsd %xmm2, 0xc0(%rdi)
  vmovsd %xmm1, 0xf8(%rdi)
  movdqu <offset:1>+0x68(%rsp), %xmm0
  vmovsd %xmm0, 0xf0(%rdi)
  movq 0xe0(%rsp), %rbx
  movq 0xe8(%rsp), %r12
  movq 0xf0(%rsp), %r13
  movq 0xf8(%rsp), %r14
  movq 0x100(%rsp), %r15
  addq $0x110, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block1:
  movl $0x800, %esi
  load_ext_name userextname0+0, %r8
  movq <offset:1>+0x18(%rsp), %rdi
  call    *%r8
  movq 0xe0(%rsp), %rbx
  movq 0xe8(%rsp), %r12
  movq 0xf0(%rsp), %r13
  movq 0xf8(%rsp), %r14
  movq 0x100(%rsp), %r15
  addq $0x110, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block3:
  movq <offset:1>+0x18(%rsp), %rdi
  movl %ebx, 0x360(%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %rax
  call    *%rax
  movq <offset:1>+8(%rsp), %r10
  addl $0x1, (%r10)
  addl $0x2, 4(%r10)
  movq 0xe0(%rsp), %rbx
  movq 0xe8(%rsp), %r12
  movq 0xf0(%rsp), %r13
  movq 0xf8(%rsp), %r14
  movq 0x100(%rsp), %r15
  addq $0x110, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block5:
  movq <offset:1>+0x18(%rsp), %rdi
  movl %r14d, 0x360(%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %r11
  call    *%r11
  movq 0xe0(%rsp), %rbx
  movq 0xe8(%rsp), %r12
  movq 0xf0(%rsp), %r13
  movq 0xf8(%rsp), %r14
  movq 0x100(%rsp), %r15
  addq $0x110, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block7:
  movq <offset:1>+0x18(%rsp), %rdi
  movl %r15d, 0x360(%rdi)
  movdqu <offset:1>+0xb8(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movdqu <offset:1>+0xc8(%rsp), %xmm6
  vmovsd %xmm6, 0xa8(%rdi)
  leal 4(%r14), %r9d
  movl %r9d, (%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %r10
  call    *%r10
  movq <offset:1>+8(%rsp), %r10
  addl $0x1, (%r10)
  addl $0x2, 4(%r10)
  movq 0xe0(%rsp), %rbx
  movq 0xe8(%rsp), %r12
  movq 0xf0(%rsp), %r13
  movq 0xf8(%rsp), %r14
  movq 0x100(%rsp), %r15
  addq $0x110, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block9:
  movq <offset:1>+0x18(%rsp), %rdi
  movl %r12d, 0x360(%rdi)
  movdqu <offset:1>+0xb8(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movdqu <offset:1>+0xc8(%rsp), %xmm6
  vmovsd %xmm6, 0xa8(%rdi)
  leal 4(%r14), %r10d
  movl %r10d, (%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %r11
  call    *%r11
  movq 0xe0(%rsp), %rbx
  movq 0xe8(%rsp), %r12
  movq 0xf0(%rsp), %r13
  movq 0xf8(%rsp), %r14
  movq 0x100(%rsp), %r15
  addq $0x110, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block11:
  movq <offset:1>+0x18(%rsp), %rdi
  movl %r12d, 0x360(%rdi)
  movdqu <offset:1>+0xb8(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movdqu <offset:1>+0x78(%rsp), %xmm5
  vpshufd $0xee, %xmm5, %xmm1
  vmovsd %xmm1, 0xf0(%rdi)
  vmovsd %xmm5, 0xe8(%rdi)
  movdqu <offset:1>+0xc8(%rsp), %xmm6
  vmovsd %xmm6, 0xa8(%rdi)
  movl $0x1f000, %r8d
  uninit  %xmm3
  vxorpd %xmm3, %xmm3, %xmm6
  vucomisd %xmm5, %xmm6
  seta %sil
  movzbl %sil, %ecx
  shll $0xf, %ecx
  vucomisd (%rip), %xmm5
  seta %dil
  movzbl %dil, %esi
  shll $0xe, %esi
  orl %esi, %ecx
  vucomisd (%rip), %xmm5
  setnp %al
  sete %dl
  andl %edx, %eax
  movzbl %al, %edi
  shll $0xd, %edi
  orl %edi, %ecx
  vucomisd (%rip), %xmm5
  setp %dl
  movzbl %dl, %eax
  shll $0xc, %eax
  orl %eax, %ecx
  movq %r8, %rdx
  andl %ecx, %edx
  notl %r8d
  movq <offset:1>+0x90(%rsp), %rdi
  andl %edi, %r8d
  orl %r8d, %edx
  movq <offset:1>+0x18(%rsp), %rdi
  movl %edx, 0x28c(%rdi)
  movdqu <offset:1>+0x98(%rsp), %xmm5
  vmovsd %xmm5, 0xd0(%rdi)
  movdqu <offset:1>+0xa8(%rsp), %xmm5
  vmovsd %xmm5, 0xc8(%rdi)
  leal 0xc(%r14), %r9d
  movl %r9d, (%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %r10
  call    *%r10
  movq <offset:1>+8(%rsp), %r10
  addl $0x2, (%r10)
  addl $0x4, 4(%r10)
  movq 0xe0(%rsp), %rbx
  movq 0xe8(%rsp), %r12
  movq 0xf0(%rsp), %r13
  movq 0xf8(%rsp), %r14
  movq 0x100(%rsp), %r15
  addq $0x110, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block13:
  movq <offset:1>+0x18(%rsp), %rdi
  movl %r13d, 0x360(%rdi)
  movdqu <offset:1>+0xb8(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movdqu <offset:1>+0x68(%rsp), %xmm0
  vmovsd %xmm0, 0xf0(%rdi)
  movdqu <offset:1>+0x78(%rsp), %xmm5
  vmovsd %xmm5, 0xe8(%rdi)
  movdqu <offset:1>+0xc8(%rsp), %xmm6
  vmovsd %xmm6, 0xa8(%rdi)
  movl $0x1f000, %r9d
  uninit  %xmm6
  vxorpd %xmm6, %xmm6, %xmm0
  vucomisd %xmm5, %xmm0
  seta %dil
  movzbl %dil, %edx
  shll $0xf, %edx
  vucomisd (%rip), %xmm5
  seta %al
  movzbl %al, %edi
  shll $0xe, %edi
  orl %edi, %edx
  vucomisd (%rip), %xmm5
  setnp %cl
  sete %r8b
  andl %r8d, %ecx
  movzbl %cl, %eax
  shll $0xd, %eax
  orl %eax, %edx
  vucomisd (%rip), %xmm5
  setp %r8b
  movzbl %r8b, %ecx
  shll $0xc, %ecx
  orl %ecx, %edx
  movq %r9, %r8
  andl %edx, %r8d
  notl %r9d
  movq <offset:1>+0x90(%rsp), %r13
  andl %r13d, %r9d
  orl %r9d, %r8d
  movq <offset:1>+0x18(%rsp), %rdi
  movl %r8d, 0x28c(%rdi)
  movdqu <offset:1>+0x98(%rsp), %xmm5
  vmovsd %xmm5, 0xd0(%rdi)
  movdqu <offset:1>+0xa8(%rsp), %xmm5
  vmovsd %xmm5, 0xc8(%rdi)
  leal 0xc(%r14), %r10d
  movl %r10d, (%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %r11
  call    *%r11
  movq 0xe0(%rsp), %rbx
  movq 0xe8(%rsp), %r12
  movq 0xf0(%rsp), %r13
  movq 0xf8(%rsp), %r14
  movq 0x100(%rsp), %r15
  addq $0x110, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block15:
  leal 8(%rbx), %ecx
  movq <offset:1>+0x18(%rsp), %rdi
  movl %ecx, 0x360(%rdi)
  movdqu <offset:1>+0xb8(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movdqu <offset:1>+0x68(%rsp), %xmm0
  vmovsd %xmm0, 0xf0(%rdi)
  movdqu <offset:1>+0x78(%rsp), %xmm5
  vmovsd %xmm5, 0xe8(%rdi)
  movdqu <offset:1>+0xc8(%rsp), %xmm6
  vmovsd %xmm6, 0xa8(%rdi)
  movl $0x1f000, %r8d
  uninit  %xmm7
  vxorpd %xmm7, %xmm7, %xmm1
  vucomisd %xmm5, %xmm1
  seta %sil
  movzbl %sil, %ecx
  shll $0xf, %ecx
  vucomisd (%rip), %xmm5
  seta %dil
  movzbl %dil, %esi
  shll $0xe, %esi
  orl %esi, %ecx
  vucomisd (%rip), %xmm5
  setnp %dl
  sete %r9b
  andl %r9d, %edx
  movzbl %dl, %edi
  shll $0xd, %edi
  orl %edi, %ecx
  vucomisd (%rip), %xmm5
  setp %dl
  movzbl %dl, %edx
  shll $0xc, %edx
  orl %edx, %ecx
  movq %r8, %rdx
  andl %ecx, %edx
  notl %r8d
  andl %r13d, %r8d
  orl %r8d, %edx
  movq <offset:1>+0x18(%rsp), %rdi
  movl %edx, 0x28c(%rdi)
  movdqu <offset:1>+0x98(%rsp), %xmm5
  vmovsd %xmm5, 0xd0(%rdi)
  movdqu <offset:1>+0xa8(%rsp), %xmm5
  vmovsd %xmm5, 0xc8(%rdi)
  leal 0x10(%r14), %r9d
  movl %r9d, (%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %r10
  call    *%r10
  movq <offset:1>+8(%rsp), %r10
  addl $0x1, (%r10)
  addl $0x2, 4(%r10)
  movq 0xe0(%rsp), %rbx
  movq 0xe8(%rsp), %r12
  movq 0xf0(%rsp), %r13
  movq 0xf8(%rsp), %r14
  movq 0x100(%rsp), %r15
  addq $0x110, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block17:
  movq <offset:1>+0x18(%rsp), %rdi
  movl %ebx, 0x360(%rdi)
  movdqu <offset:1>+0xb8(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movdqu <offset:1>+0x68(%rsp), %xmm0
  vmovsd %xmm0, 0xf0(%rdi)
  movdqu <offset:1>+0x78(%rsp), %xmm5
  vmovsd %xmm5, 0xe8(%rdi)
  movdqu <offset:1>+0xc8(%rsp), %xmm6
  vmovsd %xmm6, 0xa8(%rdi)
  movl $0x1f000, %r9d
  uninit  %xmm2
  vxorpd %xmm2, %xmm2, %xmm4
  vucomisd %xmm5, %xmm4
  seta %dil
  movzbl %dil, %edx
  shll $0xf, %edx
  vucomisd (%rip), %xmm5
  seta %al
  movzbl %al, %edi
  shll $0xe, %edi
  orl %edi, %edx
  vucomisd (%rip), %xmm5
  setnp %cl
  sete %r8b
  andl %r8d, %ecx
  movzbl %cl, %ecx
  shll $0xd, %ecx
  orl %ecx, %edx
  vucomisd (%rip), %xmm5
  setp %r8b
  movzbl %r8b, %ecx
  shll $0xc, %ecx
  orl %ecx, %edx
  movq %r9, %r8
  andl %edx, %r8d
  notl %r9d
  andl %r13d, %r9d
  orl %r9d, %r8d
  movq <offset:1>+0x18(%rsp), %rdi
  movl %r8d, 0x28c(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm4
  vmovsd %xmm4, 0xb8(%rdi)
  movdqu <offset:1>+0x98(%rsp), %xmm5
  vmovsd %xmm5, 0xd0(%rdi)
  movdqu <offset:1>+0xa8(%rsp), %xmm5
  vmovsd %xmm5, 0xc8(%rdi)
  movabsq $0x3ff0000000000000, %r10
  vmovq %r10, %xmm4
  vmovsd %xmm4, 0xc0(%rdi)
  leal 0x14(%r14), %esi
  movl %esi, (%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %rax
  call    *%rax
  movq <offset:1>+8(%rsp), %r10
  addl $0x1, (%r10)
  addl $0x2, 4(%r10)
  movq 0xe0(%rsp), %rbx
  movq 0xe8(%rsp), %r12
  movq 0xf0(%rsp), %r13
  movq 0xf8(%rsp), %r14
  movq 0x100(%rsp), %r15
  addq $0x110, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block19:
  movq <offset:1>+0x18(%rsp), %rdi
  movl %r12d, 0x360(%rdi)
  movdqu <offset:1>+0xc8(%rsp), %xmm6
  vmovsd %xmm6, 0xa8(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm3
  vmovsd %xmm3, 0xd8(%rdi)
  movdqu <offset:1>+0x98(%rsp), %xmm5
  vmovsd %xmm5, 0xd0(%rdi)
  movdqu <offset:1>+0x28(%rsp), %xmm1
  vpshufd $0xee, %xmm1, %xmm7
  vmovsd %xmm7, 0x100(%rdi)
  leal 0x1c(%r14), %ecx
  movl %ecx, (%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm4
  vmovsd %xmm4, 0xb8(%rdi)
  movdqu <offset:1>+0xb8(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movl $0x1f000, %esi
  uninit  %xmm2
  vxorpd %xmm2, %xmm2, %xmm4
  vucomisd %xmm1, %xmm4
  seta %r10b
  movzbl %r10b, %edi
  shll $0xf, %edi
  vucomisd (%rip), %xmm1
  seta %r11b
  movzbl %r11b, %r10d
  shll $0xe, %r10d
  orl %r10d, %edi
  vucomisd (%rip), %xmm1
  setnp %cl
  sete %dl
  andl %edx, %ecx
  movzbl %cl, %r11d
  shll $0xd, %r11d
  orl %r11d, %edi
  vucomisd (%rip), %xmm1
  setp %al
  movzbl %al, %ecx
  shll $0xc, %ecx
  orl %ecx, %edi
  movdqu <offset:1>+0x78(%rsp), %xmm5
  vucomisd %xmm5, %xmm4
  seta %al
  movzbl %al, %r8d
  shll $0xf, %r8d
  vucomisd (%rip), %xmm5
  seta %cl
  movzbl %cl, %ecx
  shll $0xe, %ecx
  orl %ecx, %r8d
  vucomisd (%rip), %xmm5
  setnp %dl
  sete %r9b
  andl %r9d, %edx
  movzbl %dl, %ecx
  shll $0xd, %ecx
  orl %ecx, %r8d
  vucomisd (%rip), %xmm5
  setp %r9b
  movzbl %r9b, %edx
  shll $0xc, %edx
  orl %edx, %r8d
  movq %rsi, %r9
  andl %r8d, %r9d
  movq %rsi, %r8
  notl %r8d
  andl %r13d, %r8d
  orl %r8d, %r9d
  movq %rsi, %r8
  andl %edi, %r8d
  notl %esi
  andl %r9d, %esi
  orl %esi, %r8d
  movq <offset:1>+0x18(%rsp), %rdi
  movl %r8d, 0x28c(%rdi)
  vmovsd %xmm5, 0xe8(%rdi)
  movdqu <offset:1>+0x38(%rsp), %xmm2
  vmovsd %xmm2, 0xe0(%rdi)
  movdqu <offset:1>+0xa8(%rsp), %xmm5
  vmovsd %xmm5, 0xc8(%rdi)
  vmovsd %xmm2, 0xc0(%rdi)
  vmovsd %xmm1, 0xf8(%rdi)
  movdqu <offset:1>+0x68(%rsp), %xmm0
  vmovsd %xmm0, 0xf0(%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %rcx
  call    *%rcx
  movq <offset:1>+8(%rsp), %r10
  addl $0x2, (%r10)
  addl $0x4, 4(%r10)
  movq 0xe0(%rsp), %rbx
  movq 0xe8(%rsp), %r12
  movq 0xf0(%rsp), %r13
  movq 0xf8(%rsp), %r14
  movq 0x100(%rsp), %r15
  addq $0x110, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
