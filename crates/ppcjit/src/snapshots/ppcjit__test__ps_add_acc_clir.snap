---
source: crates/ppcjit/src/test.rs
expression: clir
---
function u0:0(i64, i64, i64, i64) tail {
    ss0 = explicit_slot 8, align = 8
    sig0 = (i64, i64, i64, i64) tail
    sig1 = (i64, i64, i64) -> i8 system_v
    sig2 = (i64, i32, i64) system_v
    sig3 = (i64, i32, i64) -> i8 system_v
    sig4 = (i64, i32, i64) -> i8 system_v
    sig5 = (i64, i32, i64) -> i8 system_v
    sig6 = (i64, i32, i64) -> i8 system_v
    sig7 = (i64, i32, i8) -> i8 system_v
    sig8 = (i64, i32, i16) -> i8 system_v
    sig9 = (i64, i32, i32) -> i8 system_v
    sig10 = (i64, i32, i64) -> i8 system_v
    sig11 = (i64, i32, i32, i64) -> i8 system_v
    sig12 = (i64, i32, i32, f64) -> i8 system_v
    sig13 = (i64, i32) system_v
    sig14 = (i64) system_v
    sig15 = (i64, i16) system_v
    fn0 = u1:0 sig15
    fn1 = u0:2 sig1
    fn2 = u0:3 sig2
    fn3 = u0:4 sig3
    fn4 = u0:5 sig4
    fn5 = u0:6 sig5
    fn6 = u0:7 sig6
    fn7 = u0:8 sig7
    fn8 = u0:9 sig8
    fn9 = u0:10 sig9
    fn10 = u0:11 sig10
    fn11 = u0:12 sig11
    fn12 = u0:13 sig12
    fn13 = u0:14 sig13
    fn14 = u0:15 sig14
    fn15 = u0:16 sig14
    fn16 = u0:17 sig14
    fn17 = u0:18 sig14
    fn18 = u0:19 sig14
    fn19 = u0:20 sig14
    fn20 = u0:21 sig14
    fn21 = u0:22 sig14
    fn22 = u0:23 sig14

                                block0(v0: i64, v1: i64, v2: i64, v3: i64):
@0000                               v4 = load.i32 notrap aligned v2+680
@0000                               v5 = iconst.i32 13
@0000                               v6 = ushr v4, v5  ; v5 = 13
@0000                               v7 = band_imm v6, 1
@0000                               v8 = ireduce.i8 v7
@0000                               brif v8, block2, block1

                                block1 cold:
@0000                               v9 = iconst.i16 2048
@0000                               call fn0(v2, v9)  ; v9 = 2048
@0000                               return

                                block2:
@0000                               v10 = load.f64 notrap aligned v2+136
@0000                               v11 = load.f64 notrap aligned v2+144
@0000                               v12 = scalar_to_vector.f64x2 v10
@0000                               v13 = insertlane v12, v11, 1
@0000                               v14 = load.f64 notrap aligned v2+152
@0000                               v15 = load.f64 notrap aligned v2+160
@0000                               v16 = scalar_to_vector.f64x2 v14
@0000                               v17 = insertlane v16, v15, 1
@0000                               v18 = fadd v13, v17
@0000                               v19 = extractlane v18, 0
@0000                               v20 = extractlane v18, 1
@0000                               v21 = f64const 0.0
@0000                               v22 = fcmp lt v19, v21  ; v21 = 0.0
@0000                               v23 = fcmp gt v19, v21  ; v21 = 0.0
@0000                               v24 = fcmp eq v19, v21  ; v21 = 0.0
@0000                               v25 = fcmp uno v19, v21  ; v21 = 0.0
@0000                               v26 = load.i32 notrap aligned v2+652
@0000                               v27 = uextend.i32 v22
@0000                               v28 = uextend.i32 v23
@0000                               v29 = uextend.i32 v24
@0000                               v30 = uextend.i32 v25
@0000                               v31 = iconst.i32 0
@0000                               v32 = ishl_imm v27, 15
@0000                               v33 = ishl_imm v28, 14
@0000                               v34 = ishl_imm v29, 13
@0000                               v35 = ishl_imm v30, 12
@0000                               v36 = bor v32, v33
@0000                               v37 = bor v36, v34
@0000                               v38 = bor v37, v35
@0000                               v39 = bor v38, v31  ; v31 = 0
@0000                               v40 = iconst.i32 0x0001_f000
@0000                               v41 = bitselect v40, v39, v26  ; v40 = 0x0001_f000
@0000                               v42 = load.i32 notrap aligned v2
@0000                               v43 = iadd_imm v42, 4
@0001                               v44 = load.f64 notrap aligned v2+168
@0001                               v45 = load.f64 notrap aligned v2+176
@0001                               v46 = scalar_to_vector.f64x2 v44
@0001                               v47 = insertlane v46, v45, 1
@0001                               v48 = fadd v18, v47
@0001                               v49 = extractlane v48, 0
@0001                               v50 = extractlane v48, 1
@0001                               v51 = f64const 0.0
@0001                               v52 = fcmp lt v49, v51  ; v51 = 0.0
@0001                               v53 = fcmp gt v49, v51  ; v51 = 0.0
@0001                               v54 = fcmp eq v49, v51  ; v51 = 0.0
@0001                               v55 = fcmp uno v49, v51  ; v51 = 0.0
@0001                               v56 = uextend.i32 v52
@0001                               v57 = uextend.i32 v53
@0001                               v58 = uextend.i32 v54
@0001                               v59 = uextend.i32 v55
@0001                               v60 = iconst.i32 0
@0001                               v61 = ishl_imm v56, 15
@0001                               v62 = ishl_imm v57, 14
@0001                               v63 = ishl_imm v58, 13
@0001                               v64 = ishl_imm v59, 12
@0001                               v65 = bor v61, v62
@0001                               v66 = bor v65, v63
@0001                               v67 = bor v66, v64
@0001                               v68 = bor v67, v60  ; v60 = 0
@0001                               v69 = iconst.i32 0x0001_f000
@0001                               v70 = bitselect v69, v68, v41  ; v69 = 0x0001_f000
@0001                               v71 = iadd_imm v43, 4
@0002                               v72 = load.f64 notrap aligned v2+184
@0002                               v73 = load.f64 notrap aligned v2+192
@0002                               v74 = scalar_to_vector.f64x2 v72
@0002                               v75 = insertlane v74, v73, 1
@0002                               v76 = fadd v48, v75
@0002                               v77 = extractlane v76, 0
@0002                               v78 = extractlane v76, 1
@0002                               v79 = f64const 0.0
@0002                               v80 = fcmp lt v77, v79  ; v79 = 0.0
@0002                               v81 = fcmp gt v77, v79  ; v79 = 0.0
@0002                               v82 = fcmp eq v77, v79  ; v79 = 0.0
@0002                               v83 = fcmp uno v77, v79  ; v79 = 0.0
@0002                               v84 = uextend.i32 v80
@0002                               v85 = uextend.i32 v81
@0002                               v86 = uextend.i32 v82
@0002                               v87 = uextend.i32 v83
@0002                               v88 = iconst.i32 0
@0002                               v89 = ishl_imm v84, 15
@0002                               v90 = ishl_imm v85, 14
@0002                               v91 = ishl_imm v86, 13
@0002                               v92 = ishl_imm v87, 12
@0002                               v93 = bor v89, v90
@0002                               v94 = bor v93, v91
@0002                               v95 = bor v94, v92
@0002                               v96 = bor v95, v88  ; v88 = 0
@0002                               v97 = iconst.i32 0x0001_f000
@0002                               v98 = bitselect v97, v96, v70  ; v97 = 0x0001_f000
@0002                               v99 = iadd_imm v71, 4
@0003                               v100 = load.f64 notrap aligned v2+200
@0003                               v101 = load.f64 notrap aligned v2+208
@0003                               v102 = scalar_to_vector.f64x2 v100
@0003                               v103 = insertlane v102, v101, 1
@0003                               v104 = fadd v76, v103
@0003                               v105 = extractlane v104, 0
@0003                               v106 = extractlane v104, 1
@0003                               v107 = f64const 0.0
@0003                               v108 = fcmp lt v105, v107  ; v107 = 0.0
@0003                               v109 = fcmp gt v105, v107  ; v107 = 0.0
@0003                               v110 = fcmp eq v105, v107  ; v107 = 0.0
@0003                               v111 = fcmp uno v105, v107  ; v107 = 0.0
@0003                               v112 = uextend.i32 v108
@0003                               v113 = uextend.i32 v109
@0003                               v114 = uextend.i32 v110
@0003                               v115 = uextend.i32 v111
@0003                               v116 = iconst.i32 0
@0003                               v117 = ishl_imm v112, 15
@0003                               v118 = ishl_imm v113, 14
@0003                               v119 = ishl_imm v114, 13
@0003                               v120 = ishl_imm v115, 12
@0003                               v121 = bor v117, v118
@0003                               v122 = bor v121, v119
@0003                               v123 = bor v122, v120
@0003                               v124 = bor v123, v116  ; v116 = 0
@0003                               v125 = iconst.i32 0x0001_f000
@0003                               v126 = bitselect v125, v124, v98  ; v125 = 0x0001_f000
@0003                               v127 = iadd_imm v99, 4
                                    store notrap aligned v126, v2+652
                                    store notrap aligned v106, v2+144
                                    store notrap aligned v105, v2+136
                                    store notrap aligned v127, v2
                                    v128 = load.i32 notrap aligned v0
                                    v129 = iadd_imm v128, 4
                                    store notrap aligned v129, v0
                                    v130 = load.i32 notrap aligned v0+4
                                    v131 = iadd_imm v130, 8
                                    store notrap aligned v131, v0+4
                                    return
}
