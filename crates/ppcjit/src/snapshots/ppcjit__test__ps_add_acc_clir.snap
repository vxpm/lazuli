---
source: crates/ppcjit/src/test.rs
expression: clir
---
function u0:0(i64, i64, i64, i64) tail {
    ss0 = explicit_slot 8, align = 8
    sig0 = (i64, i64, i64, i64) tail
    sig1 = (i64, i64, i64) -> i8 system_v
    sig2 = (i64, i32, i64) system_v
    sig3 = (i64, i32, i64) -> i8 system_v
    sig4 = (i64, i32, i64) -> i8 system_v
    sig5 = (i64, i32, i64) -> i8 system_v
    sig6 = (i64, i32, i64) -> i8 system_v
    sig7 = (i64, i32, i8) -> i8 system_v
    sig8 = (i64, i32, i16) -> i8 system_v
    sig9 = (i64, i32, i32) -> i8 system_v
    sig10 = (i64, i32, i64) -> i8 system_v
    sig11 = (i64, i32, i32, i64) -> i8 system_v
    sig12 = (i64, i32, i32, f64) -> i8 system_v
    sig13 = (i64, i32) system_v
    sig14 = (i64) system_v
    sig15 = (i64, i16) system_v
    fn0 = u1:0 sig15
    fn1 = u0:2 sig1
    fn2 = u0:3 sig2
    fn3 = u0:4 sig3
    fn4 = u0:5 sig4
    fn5 = u0:6 sig5
    fn6 = u0:7 sig6
    fn7 = u0:8 sig7
    fn8 = u0:9 sig8
    fn9 = u0:10 sig9
    fn10 = u0:11 sig10
    fn11 = u0:12 sig11
    fn12 = u0:13 sig12
    fn13 = u0:14 sig13
    fn14 = u0:15 sig14
    fn15 = u0:16 sig14
    fn16 = u0:17 sig14
    fn17 = u0:18 sig14
    fn18 = u0:19 sig14
    fn19 = u0:20 sig14
    fn20 = u0:21 sig14
    fn21 = u0:22 sig14
    fn22 = u0:23 sig14

                                block0(v0: i64, v1: i64, v2: i64, v3: i64):
@0000                               v4 = load.i32 notrap aligned v2+680
@0000                               v5 = iconst.i32 13
@0000                               v6 = ushr v4, v5  ; v5 = 13
@0000                               v7 = band_imm v6, 1
@0000                               v8 = ireduce.i8 v7
@0000                               brif v8, block2, block1

                                block1 cold:
@0000                               v9 = iconst.i16 2048
@0000                               call fn0(v2, v9)  ; v9 = 2048
@0000                               return

                                block2:
@0000                               v10 = load.f64x2 notrap aligned v2+136
@0000                               v11 = load.f64x2 notrap aligned v2+152
@0000                               v12 = fadd v10, v11
@0000                               v13 = extractlane v12, 0
@0000                               v14 = f64const 0.0
@0000                               v15 = fcmp lt v13, v14  ; v14 = 0.0
@0000                               v16 = fcmp gt v13, v14  ; v14 = 0.0
@0000                               v17 = fcmp eq v13, v14  ; v14 = 0.0
@0000                               v18 = fcmp uno v13, v14  ; v14 = 0.0
@0000                               v19 = load.i32 notrap aligned v2+652
@0000                               v20 = uextend.i32 v15
@0000                               v21 = uextend.i32 v16
@0000                               v22 = uextend.i32 v17
@0000                               v23 = uextend.i32 v18
@0000                               v24 = iconst.i32 0
@0000                               v25 = ishl_imm v20, 15
@0000                               v26 = ishl_imm v21, 14
@0000                               v27 = ishl_imm v22, 13
@0000                               v28 = ishl_imm v23, 12
@0000                               v29 = bor v25, v26
@0000                               v30 = bor v29, v27
@0000                               v31 = bor v30, v28
@0000                               v32 = bor v31, v24  ; v24 = 0
@0000                               v33 = iconst.i32 0x0001_f000
@0000                               v34 = bitselect v33, v32, v19  ; v33 = 0x0001_f000
@0000                               v35 = load.i32 notrap aligned v2
@0000                               v36 = iadd_imm v35, 4
@0001                               v37 = load.f64x2 notrap aligned v2+168
@0001                               v38 = fadd v12, v37
@0001                               v39 = extractlane v38, 0
@0001                               v40 = f64const 0.0
@0001                               v41 = fcmp lt v39, v40  ; v40 = 0.0
@0001                               v42 = fcmp gt v39, v40  ; v40 = 0.0
@0001                               v43 = fcmp eq v39, v40  ; v40 = 0.0
@0001                               v44 = fcmp uno v39, v40  ; v40 = 0.0
@0001                               v45 = uextend.i32 v41
@0001                               v46 = uextend.i32 v42
@0001                               v47 = uextend.i32 v43
@0001                               v48 = uextend.i32 v44
@0001                               v49 = iconst.i32 0
@0001                               v50 = ishl_imm v45, 15
@0001                               v51 = ishl_imm v46, 14
@0001                               v52 = ishl_imm v47, 13
@0001                               v53 = ishl_imm v48, 12
@0001                               v54 = bor v50, v51
@0001                               v55 = bor v54, v52
@0001                               v56 = bor v55, v53
@0001                               v57 = bor v56, v49  ; v49 = 0
@0001                               v58 = iconst.i32 0x0001_f000
@0001                               v59 = bitselect v58, v57, v34  ; v58 = 0x0001_f000
@0001                               v60 = iadd_imm v36, 4
@0002                               v61 = load.f64x2 notrap aligned v2+184
@0002                               v62 = fadd v38, v61
@0002                               v63 = extractlane v62, 0
@0002                               v64 = f64const 0.0
@0002                               v65 = fcmp lt v63, v64  ; v64 = 0.0
@0002                               v66 = fcmp gt v63, v64  ; v64 = 0.0
@0002                               v67 = fcmp eq v63, v64  ; v64 = 0.0
@0002                               v68 = fcmp uno v63, v64  ; v64 = 0.0
@0002                               v69 = uextend.i32 v65
@0002                               v70 = uextend.i32 v66
@0002                               v71 = uextend.i32 v67
@0002                               v72 = uextend.i32 v68
@0002                               v73 = iconst.i32 0
@0002                               v74 = ishl_imm v69, 15
@0002                               v75 = ishl_imm v70, 14
@0002                               v76 = ishl_imm v71, 13
@0002                               v77 = ishl_imm v72, 12
@0002                               v78 = bor v74, v75
@0002                               v79 = bor v78, v76
@0002                               v80 = bor v79, v77
@0002                               v81 = bor v80, v73  ; v73 = 0
@0002                               v82 = iconst.i32 0x0001_f000
@0002                               v83 = bitselect v82, v81, v59  ; v82 = 0x0001_f000
@0002                               v84 = iadd_imm v60, 4
@0003                               v85 = load.f64x2 notrap aligned v2+200
@0003                               v86 = fadd v62, v85
@0003                               v87 = extractlane v86, 0
@0003                               v88 = f64const 0.0
@0003                               v89 = fcmp lt v87, v88  ; v88 = 0.0
@0003                               v90 = fcmp gt v87, v88  ; v88 = 0.0
@0003                               v91 = fcmp eq v87, v88  ; v88 = 0.0
@0003                               v92 = fcmp uno v87, v88  ; v88 = 0.0
@0003                               v93 = uextend.i32 v89
@0003                               v94 = uextend.i32 v90
@0003                               v95 = uextend.i32 v91
@0003                               v96 = uextend.i32 v92
@0003                               v97 = iconst.i32 0
@0003                               v98 = ishl_imm v93, 15
@0003                               v99 = ishl_imm v94, 14
@0003                               v100 = ishl_imm v95, 13
@0003                               v101 = ishl_imm v96, 12
@0003                               v102 = bor v98, v99
@0003                               v103 = bor v102, v100
@0003                               v104 = bor v103, v101
@0003                               v105 = bor v104, v97  ; v97 = 0
@0003                               v106 = iconst.i32 0x0001_f000
@0003                               v107 = bitselect v106, v105, v83  ; v106 = 0x0001_f000
@0003                               v108 = iadd_imm v84, 4
                                    store notrap aligned v108, v2
                                    store notrap aligned v86, v2+136
                                    store notrap aligned v107, v2+652
                                    v109 = load.i32 notrap aligned v0
                                    v110 = iadd_imm v109, 4
                                    store notrap aligned v110, v0
                                    v111 = load.i32 notrap aligned v0+4
                                    v112 = iadd_imm v111, 8
                                    store notrap aligned v112, v0+4
                                    return
}
