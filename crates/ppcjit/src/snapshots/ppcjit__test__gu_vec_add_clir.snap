---
source: crates/ppcjit/src/test.rs
expression: clir
---
function u0:0(i64, i64, i64, i64) tail {
    ss0 = explicit_slot 8, align = 8
    sig0 = (i64, i64, i64, i64) tail
    sig1 = (i64, i64, i64) -> i8 system_v
    sig2 = (i64, i32, i64) system_v
    sig3 = (i64, i32, i64) -> i8 system_v
    sig4 = (i64, i32, i64) -> i8 system_v
    sig5 = (i64, i32, i64) -> i8 system_v
    sig6 = (i64, i32, i64) -> i8 system_v
    sig7 = (i64, i32, i8) -> i8 system_v
    sig8 = (i64, i32, i16) -> i8 system_v
    sig9 = (i64, i32, i32) -> i8 system_v
    sig10 = (i64, i32, i64) -> i8 system_v
    sig11 = (i64, i32, i32, i64) -> i8 system_v
    sig12 = (i64, i32, i32, f64) -> i8 system_v
    sig13 = (i64, i32) system_v
    sig14 = (i64) system_v
    sig15 = (i64, i16) system_v
    fn0 = u1:0 sig15
    fn1 = u0:2 sig1
    fn2 = u0:3 sig2
    fn3 = u0:4 sig3
    fn4 = u0:5 sig4
    fn5 = u0:6 sig5
    fn6 = u0:7 sig6
    fn7 = u0:8 sig7
    fn8 = u0:9 sig8
    fn9 = u0:10 sig9
    fn10 = u0:11 sig10
    fn11 = u0:12 sig11
    fn12 = u0:13 sig12
    fn13 = u0:14 sig13
    fn14 = u0:15 sig14
    fn15 = u0:16 sig14
    fn16 = u0:17 sig14
    fn17 = u0:18 sig14
    fn18 = u0:19 sig14
    fn19 = u0:20 sig14
    fn20 = u0:21 sig14
    fn21 = u0:22 sig14
    fn22 = u0:23 sig14

                                block0(v0: i64, v1: i64, v2: i64, v3: i64):
@0000                               v4 = load.i32 notrap aligned v2+680
@0000                               v5 = iconst.i32 13
@0000                               v6 = ushr v4, v5  ; v5 = 13
@0000                               v7 = band_imm v6, 1
@0000                               v8 = ireduce.i8 v7
@0000                               brif v8, block2, block1

                                block1 cold:
@0000                               v9 = iconst.i16 2048
@0000                               call fn0(v2, v9)  ; v9 = 2048
@0000                               return

                                block2:
@0000                               v10 = load.i32 notrap aligned v2+20
@0000                               v11 = iadd_imm v10, 0
@0000                               v12 = load.i32 notrap aligned v2+872
@0000                               v13 = stack_addr.i64 ss0
@0000                               v14 = call fn11(v1, v11, v12, v13)
@0000                               brif v14, block4, block3

                                block3 cold:
@0000                               store.i32 notrap aligned v11, v2+864
@0000                               v15 = iconst.i16 768
@0000                               call fn0(v2, v15)  ; v15 = 768
@0000                               v16 = load.i32 notrap aligned v0
@0000                               v17 = iadd_imm v16, 1
@0000                               store notrap aligned v17, v0
@0000                               v18 = load.i32 notrap aligned v0+4
@0000                               v19 = iadd_imm v18, 2
@0000                               store notrap aligned v19, v0+4
@0000                               return

                                block4:
@0000                               v20 = stack_load.f64 ss0
@0000                               v21 = uextend.i32 v14
@0000                               v22 = iadd.i32 v11, v21
@0000                               v23 = stack_addr.i64 ss0
@0000                               v24 = call fn11(v1, v22, v12, v23)
@0000                               brif v24, block6, block5

                                block5 cold:
@0000                               store.i32 notrap aligned v22, v2+864
@0000                               v25 = iconst.i16 768
@0000                               call fn0(v2, v25)  ; v25 = 768
@0000                               return

                                block6:
@0000                               v26 = stack_load.f64 ss0
@0000                               v27 = uextend.i32 v24
@0000                               v28 = scalar_to_vector.f64x2 v20
@0000                               v29 = insertlane v28, v26, 1
@0000                               v30 = load.i32 notrap aligned v2
@0000                               v31 = iadd_imm v30, 4
@0001                               v32 = load.i32 notrap aligned v2+24
@0001                               v33 = iadd_imm v32, 0
@0001                               v34 = load.i32 notrap aligned v2+872
@0001                               v35 = stack_addr.i64 ss0
@0001                               v36 = call fn11(v1, v33, v34, v35)
@0001                               brif v36, block8, block7

                                block7 cold:
@0001                               store.i32 notrap aligned v33, v2+864
@0001                               v37 = iconst.i16 768
@0001                               store.i32 notrap aligned v31, v2
@0001                               store.f64x2 notrap aligned v29, v2+168
@0001                               call fn0(v2, v37)  ; v37 = 768
@0001                               v38 = load.i32 notrap aligned v0
@0001                               v39 = iadd_imm v38, 1
@0001                               store notrap aligned v39, v0
@0001                               v40 = load.i32 notrap aligned v0+4
@0001                               v41 = iadd_imm v40, 2
@0001                               store notrap aligned v41, v0+4
@0001                               return

                                block8:
@0001                               v42 = stack_load.f64 ss0
@0001                               v43 = uextend.i32 v36
@0001                               v44 = iadd.i32 v33, v43
@0001                               v45 = stack_addr.i64 ss0
@0001                               v46 = call fn11(v1, v44, v34, v45)
@0001                               brif v46, block10, block9

                                block9 cold:
@0001                               store.i32 notrap aligned v44, v2+864
@0001                               v47 = iconst.i16 768
@0001                               store.i32 notrap aligned v31, v2
@0001                               store.f64x2 notrap aligned v29, v2+168
@0001                               call fn0(v2, v47)  ; v47 = 768
@0001                               return

                                block10:
@0001                               v48 = stack_load.f64 ss0
@0001                               v49 = uextend.i32 v46
@0001                               v50 = scalar_to_vector.f64x2 v42
@0001                               v51 = insertlane v50, v48, 1
@0001                               v52 = iadd_imm.i32 v31, 4
@0002                               v53 = fadd.f64x2 v29, v51
@0002                               v54 = f64const 0.0
@0002                               v55 = splat.f64x2 v54  ; v54 = 0.0
@0002                               v56 = extractlane v53, 0
@0002                               v57 = extractlane v55, 0
@0002                               v58 = fcmp lt v56, v57
@0002                               v59 = fcmp gt v56, v57
@0002                               v60 = fcmp eq v56, v57
@0002                               v61 = fcmp uno v56, v57
@0002                               v62 = load.i32 notrap aligned v2+652
@0002                               v63 = uextend.i32 v58
@0002                               v64 = uextend.i32 v59
@0002                               v65 = uextend.i32 v60
@0002                               v66 = uextend.i32 v61
@0002                               v67 = iconst.i32 0
@0002                               v68 = ishl_imm v63, 15
@0002                               v69 = ishl_imm v64, 14
@0002                               v70 = ishl_imm v65, 13
@0002                               v71 = ishl_imm v66, 12
@0002                               v72 = bor v68, v69
@0002                               v73 = bor v72, v70
@0002                               v74 = bor v73, v71
@0002                               v75 = bor v74, v67  ; v67 = 0
@0002                               v76 = iconst.i32 0x0001_f000
@0002                               v77 = bitselect v76, v75, v62  ; v76 = 0x0001_f000
@0002                               v78 = iadd_imm v52, 4
@0003                               v79 = load.i32 notrap aligned v2+28
@0003                               v80 = iadd_imm v79, 0
@0003                               v81 = extractlane v53, 0
@0003                               v82 = load.i32 notrap aligned v2+872
@0003                               v83 = call fn12(v1, v80, v82, v81)
@0003                               brif v83, block12, block11

                                block11 cold:
@0003                               store.i32 notrap aligned v80, v2+864
@0003                               v84 = iconst.i16 768
@0003                               store.i32 notrap aligned v78, v2
@0003                               store.f64x2 notrap aligned v29, v2+168
@0003                               store.i32 notrap aligned v77, v2+652
@0003                               store.f64x2 notrap aligned v53, v2+232
@0003                               store.f64x2 notrap aligned v51, v2+200
@0003                               call fn0(v2, v84)  ; v84 = 768
@0003                               v85 = load.i32 notrap aligned v0
@0003                               v86 = iadd_imm v85, 2
@0003                               store notrap aligned v86, v0
@0003                               v87 = load.i32 notrap aligned v0+4
@0003                               v88 = iadd_imm v87, 4
@0003                               store notrap aligned v88, v0+4
@0003                               return

                                block12:
@0003                               v89 = uextend.i32 v83
@0003                               v90 = extractlane.f64x2 v53, 1
@0003                               v91 = iadd.i32 v80, v89
@0003                               v92 = call fn12(v1, v91, v82, v90)
@0003                               brif v92, block14, block13

                                block13 cold:
@0003                               store.i32 notrap aligned v91, v2+864
@0003                               v93 = iconst.i16 768
@0003                               store.i32 notrap aligned v78, v2
@0003                               store.f64x2 notrap aligned v29, v2+168
@0003                               store.i32 notrap aligned v77, v2+652
@0003                               store.f64x2 notrap aligned v53, v2+232
@0003                               store.f64x2 notrap aligned v51, v2+200
@0003                               call fn0(v2, v93)  ; v93 = 768
@0003                               return

                                block14:
@0003                               v94 = uextend.i32 v92
@0003                               v95 = iadd_imm.i32 v78, 4
@0004                               v96 = iadd_imm.i32 v10, 8
@0004                               v97 = load.i32 notrap aligned v2+872
@0004                               v98 = stack_addr.i64 ss0
@0004                               v99 = call fn11(v1, v96, v97, v98)
@0004                               brif v99, block16, block15

                                block15 cold:
@0004                               store.i32 notrap aligned v96, v2+864
@0004                               v100 = iconst.i16 768
@0004                               store.i32 notrap aligned v95, v2
@0004                               store.f64x2 notrap aligned v29, v2+168
@0004                               store.i32 notrap aligned v77, v2+652
@0004                               store.f64x2 notrap aligned v53, v2+232
@0004                               store.f64x2 notrap aligned v51, v2+200
@0004                               call fn0(v2, v100)  ; v100 = 768
@0004                               v101 = load.i32 notrap aligned v0
@0004                               v102 = iadd_imm v101, 1
@0004                               store notrap aligned v102, v0
@0004                               v103 = load.i32 notrap aligned v0+4
@0004                               v104 = iadd_imm v103, 2
@0004                               store notrap aligned v104, v0+4
@0004                               return

                                block16:
@0004                               v105 = stack_load.f64 ss0
@0004                               v106 = uextend.i32 v99
@0004                               v107 = f64const 0x1.0000000000000p0
@0004                               v108 = scalar_to_vector.f64x2 v105
@0004                               v109 = insertlane v108, v107, 1  ; v107 = 0x1.0000000000000p0
@0004                               v110 = iadd_imm.i32 v95, 4
@0005                               v111 = iadd_imm.i32 v32, 8
@0005                               v112 = load.i32 notrap aligned v2+872
@0005                               v113 = stack_addr.i64 ss0
@0005                               v114 = call fn11(v1, v111, v112, v113)
@0005                               brif v114, block18, block17

                                block17 cold:
@0005                               store.i32 notrap aligned v111, v2+864
@0005                               v115 = iconst.i16 768
@0005                               store.i32 notrap aligned v110, v2
@0005                               store.f64x2 notrap aligned v29, v2+168
@0005                               store.i32 notrap aligned v77, v2+652
@0005                               store.f64x2 notrap aligned v53, v2+232
@0005                               store.f64x2 notrap aligned v51, v2+200
@0005                               store.f64x2 notrap aligned v109, v2+184
@0005                               call fn0(v2, v115)  ; v115 = 768
@0005                               v116 = load.i32 notrap aligned v0
@0005                               v117 = iadd_imm v116, 1
@0005                               store notrap aligned v117, v0
@0005                               v118 = load.i32 notrap aligned v0+4
@0005                               v119 = iadd_imm v118, 2
@0005                               store notrap aligned v119, v0+4
@0005                               return

                                block18:
@0005                               v120 = stack_load.f64 ss0
@0005                               v121 = uextend.i32 v114
@0005                               v122 = f64const 0x1.0000000000000p0
@0005                               v123 = scalar_to_vector.f64x2 v120
@0005                               v124 = insertlane v123, v122, 1  ; v122 = 0x1.0000000000000p0
@0005                               v125 = iadd_imm.i32 v110, 4
@0006                               v126 = fadd.f64x2 v109, v124
@0006                               v127 = f64const 0.0
@0006                               v128 = splat.f64x2 v127  ; v127 = 0.0
@0006                               v129 = extractlane v126, 0
@0006                               v130 = extractlane v128, 0
@0006                               v131 = fcmp lt v129, v130
@0006                               v132 = fcmp gt v129, v130
@0006                               v133 = fcmp eq v129, v130
@0006                               v134 = fcmp uno v129, v130
@0006                               v135 = uextend.i32 v131
@0006                               v136 = uextend.i32 v132
@0006                               v137 = uextend.i32 v133
@0006                               v138 = uextend.i32 v134
@0006                               v139 = iconst.i32 0
@0006                               v140 = ishl_imm v135, 15
@0006                               v141 = ishl_imm v136, 14
@0006                               v142 = ishl_imm v137, 13
@0006                               v143 = ishl_imm v138, 12
@0006                               v144 = bor v140, v141
@0006                               v145 = bor v144, v142
@0006                               v146 = bor v145, v143
@0006                               v147 = bor v146, v139  ; v139 = 0
@0006                               v148 = iconst.i32 0x0001_f000
@0006                               v149 = bitselect v148, v147, v77  ; v148 = 0x0001_f000
@0006                               v150 = iadd_imm v125, 4
@0007                               v151 = iadd_imm.i32 v79, 8
@0007                               v152 = extractlane v126, 0
@0007                               v153 = load.i32 notrap aligned v2+872
@0007                               v154 = call fn12(v1, v151, v153, v152)
@0007                               brif v154, block20, block19

                                block19 cold:
@0007                               store.i32 notrap aligned v151, v2+864
@0007                               v155 = iconst.i16 768
@0007                               store.f64x2 notrap aligned v126, v2+248
@0007                               store.i32 notrap aligned v150, v2
@0007                               store.f64x2 notrap aligned v29, v2+168
@0007                               store.i32 notrap aligned v149, v2+652
@0007                               store.f64x2 notrap aligned v53, v2+232
@0007                               store.f64x2 notrap aligned v124, v2+216
@0007                               store.f64x2 notrap aligned v51, v2+200
@0007                               store.f64x2 notrap aligned v109, v2+184
@0007                               call fn0(v2, v155)  ; v155 = 768
@0007                               v156 = load.i32 notrap aligned v0
@0007                               v157 = iadd_imm v156, 2
@0007                               store notrap aligned v157, v0
@0007                               v158 = load.i32 notrap aligned v0+4
@0007                               v159 = iadd_imm v158, 4
@0007                               store notrap aligned v159, v0+4
@0007                               return

                                block20:
@0007                               v160 = uextend.i32 v154
@0007                               v161 = iadd_imm.i32 v150, 4
                                    store.f64x2 notrap aligned v126, v2+248
                                    store notrap aligned v161, v2
                                    store.f64x2 notrap aligned v29, v2+168
                                    store.i32 notrap aligned v149, v2+652
                                    store.f64x2 notrap aligned v53, v2+232
                                    store.f64x2 notrap aligned v124, v2+216
                                    store.f64x2 notrap aligned v51, v2+200
                                    store.f64x2 notrap aligned v109, v2+184
                                    return
}
