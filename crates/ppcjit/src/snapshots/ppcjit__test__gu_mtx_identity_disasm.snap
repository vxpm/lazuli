---
source: crates/ppcjit/src/test.rs
expression: disasm
---
  pushq %rbp
  unwind PushFrameRegs { offset_upward_to_caller_sp: 16 }
  movq %rsp, %rbp
  unwind DefineNewFrame { offset_upward_to_caller_sp: 16, offset_downward_to_clobbers: 48 }
  subq $0xa0, %rsp
  movq %rbx, 0x70(%rsp)
  unwind SaveReg { clobber_offset: 0, reg: p3i }
  movq %r12, 0x78(%rsp)
  unwind SaveReg { clobber_offset: 8, reg: p12i }
  movq %r13, 0x80(%rsp)
  unwind SaveReg { clobber_offset: 16, reg: p13i }
  movq %r14, 0x88(%rsp)
  unwind SaveReg { clobber_offset: 24, reg: p14i }
  movq %r15, 0x90(%rsp)
  unwind SaveReg { clobber_offset: 32, reg: p15i }
block0:
  movq %rdi, %r13
  movq %rsi, <offset:1>+8(%rsp)
  movl 0x2a8(%rdx), %r9d
  movq %rdx, <offset:1>+0x10(%rsp)
  shrl $0xd, %r9d
  testb $0x1, %r9b
  jnz     label2; j label1
block2:
  movq <offset:1>+0x10(%rsp), %rdi
  movl 0x84(%rdi), %r12d
  movq %r12, %rax
  shrl $0x11, %eax
  movq (%rcx, %rax, 8), %rax
  movq %rcx, %rbx
  testq %rax, %rax
  jnz     label6; j label3
block5:
  movq %r13, %r15
  movl <offset:1>+(%rsp), %r13d
  movq <offset:1>+0x10(%rsp), %rdi
  jmp     label7
block6:
  movq %r13, %r15
  movq %r12, %rcx
  andl $0x1ffff, %ecx
  movl (%rax, %rcx), %r13d
  bswapl %r13d
  movq <offset:1>+0x10(%rsp), %rdi
  jmp     label7
block7:
  movq <offset:1>+0x10(%rsp), %rdi
  movl (%rdi), %r14d
  leal 4(%r12), %ecx
  shrl $0x11, %ecx
  movq %rbx, %r8
  movq (%r8, %rcx, 8), %rdx
  testq %rdx, %rdx
  jnz     label11; j label8
block10:
  movl <offset:1>+(%rsp), %r12d
  movq <offset:1>+0x10(%rsp), %rdi
  jmp     label12
block11:
  leal 4(%r12), %r9d
  andl $0x1ffff, %r9d
  movl (%rdx, %r9), %r12d
  bswapl %r12d
  movq <offset:1>+0x10(%rsp), %rdi
  jmp     label12
block12:
  movq <offset:1>+0x10(%rsp), %rdi
  movl 0x14(%rdi), %ebx
  movl 0x368(%rdi), %edx
  movq %rdx, <offset:1>+0x38(%rsp)
  leal 8(%rbx), %esi
  vmovd %r13d, %xmm7
  uninit  %xmm5
  vxorpd %xmm5, %xmm5, %xmm0
  vcvtss2sd %xmm7, %xmm0, %xmm1
  vpshufd $0x44, %xmm1, %xmm7
  movdqu %xmm7, <offset:1>+0x58(%rsp)
  load_ext_name userextname12+0, %r11
  movq <offset:1>+8(%rsp), %rdi
  movdqu <offset:1>+0x58(%rsp), %xmm0
  call    *%r11
  testb %al, %al
  jnz     label14; j label13
block14:
  movdqu <offset:1>+0x58(%rsp), %xmm7
  movzbl %al, %edi
  leal 8(%rbx, %rdi), %r13d
  vpshufd $0xee, %xmm7, %xmm2
  movdqu %xmm2, <offset:1>+0x48(%rsp)
  load_ext_name userextname12+0, %rax
  movq <offset:1>+0x38(%rsp), %rdx
  movq %r13, %rsi
  movq <offset:1>+8(%rsp), %rdi
  movdqu <offset:1>+0x48(%rsp), %xmm0
  call    *%rax
  testb %al, %al
  jnz     label16; j label15
block16:
  movq <offset:1>+0x10(%rsp), %rdi
  movl 0x368(%rdi), %edx
  movq %rdx, <offset:1>+0x38(%rsp)
  leal 0x18(%rbx), %esi
  load_ext_name userextname12+0, %rax
  movq <offset:1>+8(%rsp), %rdi
  movdqu <offset:1>+0x58(%rsp), %xmm0
  call    *%rax
  testb %al, %al
  jnz     label18; j label17
block18:
  movzbl %al, %r9d
  leal 0x18(%rbx, %r9), %r13d
  load_ext_name userextname12+0, %r9
  movq <offset:1>+0x38(%rsp), %rdx
  movq %r13, %rsi
  movq <offset:1>+8(%rsp), %rdi
  movdqu <offset:1>+0x48(%rsp), %xmm0
  call    *%r9
  testb %al, %al
  jnz     label20; j label19
block20:
  movq <offset:1>+0x10(%rsp), %rdi
  movl 0x368(%rdi), %edx
  movq %rdx, <offset:1>+0x38(%rsp)
  leal 0x20(%rbx), %esi
  load_ext_name userextname12+0, %rax
  movq <offset:1>+8(%rsp), %rdi
  movdqu <offset:1>+0x58(%rsp), %xmm0
  call    *%rax
  testb %al, %al
  jnz     label22; j label21
block22:
  movzbl %al, %r10d
  leal 0x20(%rbx, %r10), %r13d
  load_ext_name userextname12+0, %r10
  movq <offset:1>+0x38(%rsp), %rdx
  movq %r13, %rsi
  movq <offset:1>+8(%rsp), %rdi
  movdqu <offset:1>+0x48(%rsp), %xmm0
  call    *%r10
  testb %al, %al
  jnz     label24; j label23
block24:
  movq <offset:1>+0x10(%rsp), %rdi
  movl 0x368(%rdi), %edx
  movq %rdx, <offset:1>+0x38(%rsp)
  leal 0x10(%rbx), %esi
  load_ext_name userextname12+0, %rcx
  movq <offset:1>+8(%rsp), %rdi
  movdqu <offset:1>+0x58(%rsp), %xmm0
  call    *%rcx
  testb %al, %al
  jnz     label26; j label25
block26:
  movzbl %al, %edi
  leal 0x10(%rbx, %rdi), %r13d
  vmovd %r12d, %xmm3
  uninit  %xmm1
  vxorpd %xmm1, %xmm1, %xmm4
  vcvtss2sd %xmm3, %xmm4, %xmm5
  vpshufd $0x44, %xmm5, %xmm3
  vpshufd $0xee, %xmm3, %xmm7
  movdqu %xmm7, <offset:1>+0x18(%rsp)
  movdqu %xmm3, <offset:1>+0x28(%rsp)
  load_ext_name userextname12+0, %rax
  movq <offset:1>+0x38(%rsp), %rdx
  movq %r13, %rsi
  movq <offset:1>+8(%rsp), %rdi
  movdqu <offset:1>+0x18(%rsp), %xmm0
  call    *%rax
  testb %al, %al
  jnz     label28; j label27
block28:
  movq <offset:1>+0x10(%rsp), %rdi
  movl 0x368(%rdi), %edx
  movq %rdx, %r12
  load_ext_name userextname12+0, %r9
  movq %rbx, %rsi
  movq <offset:1>+8(%rsp), %rdi
  movdqu <offset:1>+0x18(%rsp), %xmm0
  call    *%r9
  testb %al, %al
  jnz     label30; j label29
block30:
  movzbl %al, %edx
  leal (%rbx, %rdx), %r13d
  load_ext_name userextname12+0, %r8
  movq %r12, %rdx
  movq %r13, %rsi
  movq <offset:1>+8(%rsp), %rdi
  movdqu <offset:1>+0x58(%rsp), %xmm0
  call    *%r8
  testb %al, %al
  jnz     label32; j label31
block32:
  movq <offset:1>+0x10(%rsp), %rdi
  movl 0x368(%rdi), %edx
  movq %rdx, %r12
  leal 0x28(%rbx), %esi
  load_ext_name userextname12+0, %rax
  movq <offset:1>+8(%rsp), %rdi
  movdqu <offset:1>+0x18(%rsp), %xmm0
  call    *%rax
  testb %al, %al
  jnz     label34; j label33
block34:
  movzbl %al, %r10d
  leal 0x28(%rbx, %r10), %r13d
  load_ext_name userextname12+0, %r10
  movq %r12, %rdx
  movq <offset:1>+8(%rsp), %rdi
  movq %r13, %rsi
  movdqu <offset:1>+0x58(%rsp), %xmm0
  call    *%r10
  testb %al, %al
  jnz     label36; j label35
block36:
  movq <offset:1>+0x10(%rsp), %rdi
  movdqu <offset:1>+0x18(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vmovsd %xmm7, 0xa8(%rdi)
  vmovsd %xmm3, 0xa0(%rdi)
  movdqu <offset:1>+0x28(%rsp), %xmm3
  vmovsd %xmm3, 0x98(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm2
  vmovsd %xmm2, 0x90(%rdi)
  vmovsd %xmm7, 0x88(%rdi)
  vmovsd %xmm7, 0xc0(%rdi)
  leal 0x28(%r14), %edi
  movq <offset:1>+0x10(%rsp), %rax
  movl %edi, (%rax)
  movq <offset:1>+0x10(%rsp), %rdi
  movdqu <offset:1>+0x18(%rsp), %xmm3
  vmovsd %xmm3, 0xb8(%rdi)
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block1:
  movl $0x800, %esi
  load_ext_name userextname0+0, %rax
  movq <offset:1>+0x10(%rsp), %rdi
  call    *%rax
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block3:
  leaq <offset:1>+(%rsp), %rdx
  load_ext_name userextname5+0, %r8
  movq %r12, %rsi
  movq <offset:1>+8(%rsp), %rdi
  call    *%r8
  testb %al, %al
  jnz     label5; j label4
block4:
  movq <offset:1>+0x10(%rsp), %rdi
  movl %r12d, 0x360(%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %r10
  call    *%r10
  movq %r13, %r15
  addl $0x1, (%r15)
  addl $0x2, 4(%r15)
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block8:
  leal 4(%r12), %esi
  leaq <offset:1>+(%rsp), %rdx
  load_ext_name userextname5+0, %r9
  movq <offset:1>+8(%rsp), %rdi
  call    *%r9
  testb %al, %al
  jnz     label10; j label9
block9:
  leal 4(%r12), %r11d
  movq <offset:1>+0x10(%rsp), %rdi
  movl %r11d, 0x360(%rdi)
  vmovd %r13d, %xmm7
  uninit  %xmm5
  vxorpd %xmm5, %xmm5, %xmm0
  vcvtss2sd %xmm7, %xmm0, %xmm1
  vpshufd $0x44, %xmm1, %xmm7
  vmovupd %xmm7, 0x88(%rdi)
  leal 4(%r14), %edi
  movq <offset:1>+0x10(%rsp), %r8
  movl %edi, (%r8)
  movl $0x300, %esi
  load_ext_name userextname0+0, %rax
  movq <offset:1>+0x10(%rsp), %rdi
  call    *%rax
  addl $0x1, (%r15)
  addl $0x2, 4(%r15)
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block13:
  leal 8(%rbx), %edi
  movq <offset:1>+0x10(%rsp), %rsi
  movl %edi, 0x360(%rsi)
  vmovd %r12d, %xmm2
  uninit  %xmm0
  vxorpd %xmm0, %xmm0, %xmm3
  vcvtss2sd %xmm2, %xmm3, %xmm4
  vpshufd $0x44, %xmm4, %xmm2
  movq <offset:1>+0x10(%rsp), %rdi
  vmovupd %xmm2, 0x98(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vpshufd $0xee, %xmm7, %xmm3
  vmovsd %xmm3, 0x90(%rdi)
  vmovsd %xmm7, 0x88(%rdi)
  leal 8(%r14), %r8d
  movl %r8d, (%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %r9
  call    *%r9
  addl $0x1, (%r15)
  addl $0x2, 4(%r15)
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block15:
  movq <offset:1>+0x10(%rsp), %rdi
  movl %r13d, 0x360(%rdi)
  vmovd %r12d, %xmm5
  uninit  %xmm3
  vxorpd %xmm3, %xmm3, %xmm6
  vcvtss2sd %xmm5, %xmm6, %xmm7
  vpshufd $0x44, %xmm7, %xmm5
  vmovupd %xmm5, 0x98(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm2
  vmovsd %xmm2, 0x90(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vmovsd %xmm7, 0x88(%rdi)
  leal 8(%r14), %r10d
  movl %r10d, (%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %r11
  call    *%r11
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block17:
  leal 0x18(%rbx), %ecx
  movq <offset:1>+0x10(%rsp), %rdi
  movl %ecx, 0x360(%rdi)
  vmovd %r12d, %xmm6
  uninit  %xmm4
  vxorpd %xmm4, %xmm4, %xmm7
  vcvtss2sd %xmm6, %xmm7, %xmm0
  vpshufd $0x44, %xmm0, %xmm6
  vpshufd $0xee, %xmm6, %xmm7
  vmovsd %xmm7, 0xb0(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm0
  vmovsd %xmm0, 0xa8(%rdi)
  vmovsd %xmm7, 0xa0(%rdi)
  vmovsd %xmm6, 0x98(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm2
  vmovsd %xmm2, 0x90(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vmovsd %xmm7, 0x88(%rdi)
  leal 0x10(%r14), %edi
  movq <offset:1>+0x10(%rsp), %rsi
  movl %edi, (%rsi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %rax
  movq <offset:1>+0x10(%rsp), %rdi
  call    *%rax
  addl $0x2, (%r15)
  addl $0x4, 4(%r15)
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block19:
  movq <offset:1>+0x10(%rsp), %rdi
  movl %r13d, 0x360(%rdi)
  vmovd %r12d, %xmm4
  uninit  %xmm2
  vxorpd %xmm2, %xmm2, %xmm5
  vcvtss2sd %xmm4, %xmm5, %xmm6
  vpshufd $0x44, %xmm6, %xmm4
  vpshufd $0xee, %xmm4, %xmm5
  vmovsd %xmm5, 0xb0(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vmovsd %xmm7, 0xa8(%rdi)
  vmovsd %xmm5, 0xa0(%rdi)
  vmovsd %xmm4, 0x98(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm2
  vmovsd %xmm2, 0x90(%rdi)
  vmovsd %xmm7, 0x88(%rdi)
  leal 0x10(%r14), %r9d
  movl %r9d, (%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %r10
  call    *%r10
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block21:
  leal 0x20(%rbx), %eax
  movq <offset:1>+0x10(%rsp), %rdi
  movl %eax, 0x360(%rdi)
  vmovd %r12d, %xmm0
  uninit  %xmm6
  vxorpd %xmm6, %xmm6, %xmm1
  vcvtss2sd %xmm0, %xmm1, %xmm2
  vpshufd $0x44, %xmm2, %xmm1
  vpshufd $0xee, %xmm1, %xmm0
  vmovsd %xmm0, 0xb0(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vmovsd %xmm7, 0xa8(%rdi)
  vmovsd %xmm0, 0xa0(%rdi)
  vmovsd %xmm1, 0x98(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm2
  vmovsd %xmm2, 0x90(%rdi)
  vmovsd %xmm7, 0x88(%rdi)
  vmovsd %xmm7, 0xc0(%rdi)
  leal 0x18(%r14), %edi
  movq <offset:1>+0x10(%rsp), %rax
  movl %edi, (%rax)
  movq <offset:1>+0x10(%rsp), %rdi
  vmovsd %xmm0, 0xb8(%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %rcx
  call    *%rcx
  addl $0x2, (%r15)
  addl $0x4, 4(%r15)
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block23:
  movq <offset:1>+0x10(%rsp), %rdi
  movl %r13d, 0x360(%rdi)
  vmovd %r12d, %xmm0
  uninit  %xmm6
  vxorpd %xmm6, %xmm6, %xmm1
  vcvtss2sd %xmm0, %xmm1, %xmm2
  vpshufd $0x44, %xmm2, %xmm1
  vpshufd $0xee, %xmm1, %xmm0
  vmovsd %xmm0, 0xb0(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vmovsd %xmm7, 0xa8(%rdi)
  vmovsd %xmm0, 0xa0(%rdi)
  vmovsd %xmm1, 0x98(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm2
  vmovsd %xmm2, 0x90(%rdi)
  vmovsd %xmm7, 0x88(%rdi)
  vmovsd %xmm7, 0xc0(%rdi)
  leal 0x18(%r14), %r11d
  movl %r11d, (%rdi)
  vmovsd %xmm0, 0xb8(%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %rax
  call    *%rax
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block25:
  leal 0x10(%rbx), %r8d
  movq <offset:1>+0x10(%rsp), %rdi
  movl %r8d, 0x360(%rdi)
  vmovd %r12d, %xmm6
  uninit  %xmm4
  vxorpd %xmm4, %xmm4, %xmm7
  vcvtss2sd %xmm6, %xmm7, %xmm0
  vpshufd $0x44, %xmm0, %xmm7
  vpshufd $0xee, %xmm7, %xmm6
  vmovsd %xmm6, 0xb0(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm0
  vmovsd %xmm0, 0xa8(%rdi)
  vmovsd %xmm6, 0xa0(%rdi)
  vmovsd %xmm7, 0x98(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm2
  vmovsd %xmm2, 0x90(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vmovsd %xmm7, 0x88(%rdi)
  vmovsd %xmm7, 0xc0(%rdi)
  leal 0x1c(%r14), %edx
  movl %edx, (%rdi)
  vmovsd %xmm6, 0xb8(%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %r9
  call    *%r9
  addl $0x1, (%r15)
  addl $0x2, 4(%r15)
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block27:
  movq <offset:1>+0x10(%rsp), %rdi
  movl %r13d, 0x360(%rdi)
  movdqu <offset:1>+0x18(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vmovsd %xmm7, 0xa8(%rdi)
  vmovsd %xmm3, 0xa0(%rdi)
  movdqu <offset:1>+0x28(%rsp), %xmm3
  vmovsd %xmm3, 0x98(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm2
  vmovsd %xmm2, 0x90(%rdi)
  vmovsd %xmm7, 0x88(%rdi)
  vmovsd %xmm7, 0xc0(%rdi)
  leal 0x1c(%r14), %eax
  movl %eax, (%rdi)
  movdqu <offset:1>+0x18(%rsp), %xmm3
  vmovsd %xmm3, 0xb8(%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %rdx
  call    *%rdx
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block29:
  movq <offset:1>+0x10(%rsp), %rdi
  movl %ebx, 0x360(%rdi)
  movdqu <offset:1>+0x18(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vmovsd %xmm7, 0xa8(%rdi)
  vmovsd %xmm3, 0xa0(%rdi)
  movdqu <offset:1>+0x28(%rsp), %xmm3
  vmovsd %xmm3, 0x98(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm2
  vmovsd %xmm2, 0x90(%rdi)
  vmovsd %xmm7, 0x88(%rdi)
  vmovsd %xmm7, 0xc0(%rdi)
  leal 0x20(%r14), %r10d
  movl %r10d, (%rdi)
  movdqu <offset:1>+0x18(%rsp), %xmm3
  vmovsd %xmm3, 0xb8(%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %rax
  call    *%rax
  addl $0x1, (%r15)
  addl $0x2, 4(%r15)
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block31:
  movq <offset:1>+0x10(%rsp), %rdi
  movl %r13d, 0x360(%rdi)
  movdqu <offset:1>+0x18(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vmovsd %xmm7, 0xa8(%rdi)
  vmovsd %xmm3, 0xa0(%rdi)
  movdqu <offset:1>+0x28(%rsp), %xmm3
  vmovsd %xmm3, 0x98(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm2
  vmovsd %xmm2, 0x90(%rdi)
  vmovsd %xmm7, 0x88(%rdi)
  vmovsd %xmm7, 0xc0(%rdi)
  leal 0x20(%r14), %r8d
  movl %r8d, (%rdi)
  movdqu <offset:1>+0x18(%rsp), %xmm3
  vmovsd %xmm3, 0xb8(%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %r10
  call    *%r10
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block33:
  leal 0x28(%rbx), %eax
  movq <offset:1>+0x10(%rsp), %rdi
  movl %eax, 0x360(%rdi)
  movdqu <offset:1>+0x18(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vmovsd %xmm7, 0xa8(%rdi)
  vmovsd %xmm3, 0xa0(%rdi)
  movdqu <offset:1>+0x28(%rsp), %xmm3
  vmovsd %xmm3, 0x98(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm2
  vmovsd %xmm2, 0x90(%rdi)
  vmovsd %xmm7, 0x88(%rdi)
  vmovsd %xmm7, 0xc0(%rdi)
  leal 0x24(%r14), %edi
  movq <offset:1>+0x10(%rsp), %r9
  movl %edi, (%r9)
  movq <offset:1>+0x10(%rsp), %rdi
  movdqu <offset:1>+0x18(%rsp), %xmm3
  vmovsd %xmm3, 0xb8(%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %rcx
  call    *%rcx
  addl $0x1, (%r15)
  addl $0x2, 4(%r15)
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
block35:
  movq <offset:1>+0x10(%rsp), %rdi
  movl %r13d, 0x360(%rdi)
  movdqu <offset:1>+0x18(%rsp), %xmm3
  vmovsd %xmm3, 0xb0(%rdi)
  movdqu <offset:1>+0x58(%rsp), %xmm7
  vmovsd %xmm7, 0xa8(%rdi)
  vmovsd %xmm3, 0xa0(%rdi)
  movdqu <offset:1>+0x28(%rsp), %xmm3
  vmovsd %xmm3, 0x98(%rdi)
  movdqu <offset:1>+0x48(%rsp), %xmm2
  vmovsd %xmm2, 0x90(%rdi)
  vmovsd %xmm7, 0x88(%rdi)
  vmovsd %xmm7, 0xc0(%rdi)
  leal 0x24(%r14), %r11d
  movl %r11d, (%rdi)
  movdqu <offset:1>+0x18(%rsp), %xmm3
  vmovsd %xmm3, 0xb8(%rdi)
  movl $0x300, %esi
  load_ext_name userextname0+0, %rax
  call    *%rax
  movq 0x70(%rsp), %rbx
  movq 0x78(%rsp), %r12
  movq 0x80(%rsp), %r13
  movq 0x88(%rsp), %r14
  movq 0x90(%rsp), %r15
  addq $0xa0, %rsp
  movq %rbp, %rsp
  popq %rbp
  retq
